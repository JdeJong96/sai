{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895cb5d-b84a-4604-8d8e-48269134e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for this notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6092a6-b0df-4b5b-a873-2ae78086ce8e",
   "metadata": {},
   "source": [
    "#### The script functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9804990a-54dc-4515-9f04-920f094402ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cftime\n",
    "import numpy\n",
    "import datetime\n",
    "import time\n",
    "import glob, os\n",
    "import sys\n",
    "import math\n",
    "import netCDF4 as netcdf\n",
    "import multiprocessing as mp\n",
    "\n",
    "dry_run\t\t\t= False # set False to do computing\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "# uncomment for RCP8.5 hres data\n",
    "run_ensemble\t= 1 # ensemble number must be provided as script argument\n",
    "run_year_start\t= 2092 # [2002, 2092]\n",
    "experiment_name = 'b.e10.B_RCP8.5_CO2_CAM5.f02_t12.started_'+str(run_year_start)+'-12.'+str(run_ensemble).zfill(3)\n",
    "directory_data  = f'/projects/0/prace_imau/prace_2013081679/cesm1_0_4/f02_t12/{experiment_name}/OUTPUT/atm/hist/3h/'\n",
    "stream\t\t  \t= 'h1'\n",
    "directory\t\t= f'/home/jasperdj/files_rene/RCP.started_{run_year_start}.{run_ensemble:03d}.test/'\n",
    "gridfile\t\t= '/home/jasperdj/files_rene/Atmosphere_0_25_DX_DY_AREA.nc'\n",
    "NOUT\t\t\t= 8 # number of time steps per output file (one day)\n",
    "\n",
    "# # uncomment for SAI hres data\n",
    "# run_ensemble\t= sys.argv[1] # ensemble number must be provided as script argument\n",
    "# run_year_start\t= 2092 # [2092]\n",
    "# experiment_name = 'hres_b.e10.B2000_CAM5.f02_t12.started_'+str(run_year_start)+'-12.'+str(run_ensemble).zfill(3)\n",
    "# directory_data  = '/projects/0/nwo2021025/archive/'+experiment_name+'/atm/hist/'\n",
    "# stream\t\t  \t= 'h5'\n",
    "# directory\t\t= '/home/jasperdj/files_rene/SAI.started_'+str(run_year_start)+'.'+str(run_ensemble).zfill(3)+'/'\n",
    "# gridfile\t\t= '/home/jasperdj/files_rene/Atmosphere_0_25_DX_DY_AREA.nc'\n",
    "# NOUT\t\t\t= 8 # number of time steps per output file (one day)\n",
    "\n",
    "# # uncomment for SAI mres (0.5degree) data\n",
    "# experiment_name = 'mres_b.e10.B2000_CAM5.f05_t12.001'\n",
    "# directory_data\t= '/projects/0/nwo2021025/archive/'+experiment_name+'/atm/hist/'\n",
    "# stream\t\t\t= 'h4'\n",
    "# stream3D\t\t= 'h3' # only used for mres to calculate U250, V250 and T850\n",
    "# directory\t\t= '/home/jasperdj/files_rene/SAI.mres/'\n",
    "# gridfile\t\t= '/home/jasperdj/files_rene/Atmosphere_0_5_DX_DY_AREA.nc'\n",
    "# NOUT\t\t\t= 4 # number of time steps per output file (one day)\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# input data\n",
    "files = glob.glob(directory_data+experiment_name+'.cam2.'+stream+'.*.nc')\n",
    "files.sort() #Sort the files on date\n",
    "\n",
    "LATMIN = -60\n",
    "LATMAX = 60 \n",
    "RADIUSEARTH=6371000.0\n",
    "RVTHRESHOLD=6.0 * 10**(-5.0) # minimum for RV@850hPa\n",
    "RVDIFFTHRESHOLD=6.0 * 10**(-5.0) # minimum for RV@850hPa - RV@250hPa\n",
    "CORETEMPTHRESHOLD=0.0 # minimum temperature anomaly core w.r.t. 8x8 degree area\n",
    "FIELDSIZE=8 # (degrees N x E) size of field to calculate reference temperature\n",
    "U10THRESHOLD=10 # (m/s) minimum 10m wind speed\n",
    "U10THRESHOLD_MAXRADIUS=100 # (km) U10 should be 10m/s within 100km\n",
    "RVDISTMIN=250 # (km) min. distance between maxima (if less, only the one with lower PSL counts)\n",
    "\n",
    "\n",
    "def chunk_data(files):\n",
    "\t\"\"\"divide data into daily chunks\"\"\"\n",
    "\tn = 0 \n",
    "# \tdt = 1/NOUT # output time step in days\n",
    "\twith netcdf.Dataset(files[0],'r') as fh:\n",
    "\t\ttime = fh.variables['time'][:]\n",
    "\t\tif 'time: mean' in getattr(fh['U850'], 'cell_methods', ''):\n",
    "\t\t\ttime = time - 0.5*dt\n",
    "\t\tdates = [cftime.num2date(t, fh['time'].units, fh['time'].calendar).strftime(\"%Y%m%d\") for t in time]\n",
    "\t\tchunks = [[dates[0],[0],0,0]]\n",
    "\tfor fid in range(len(files)):\n",
    "\t\twith netcdf.Dataset(files[fid],'r') as fh:\n",
    "\t\t\ttime = fh.variables['time'][:]\n",
    "\t\t\tif 'time: mean' in getattr(fh['U850'], 'cell_methods', ''):\n",
    "\t\t\t\ttime = time - 0.5*dt\n",
    "\t\t\tdates = [cftime.num2date(t, fh['time'].units, fh['time'].calendar).strftime(\"%Y%m%d\") for t in time]\n",
    "\t\t\tfor i,newdate in enumerate(dates):\n",
    "\t\t\t\t(olddate, fids0, i0, n0) = chunks[-1]\n",
    "\t\t\t\tif newdate != olddate:\n",
    "\t\t\t\t\tif fids0[-1] != fid and i!=0:\n",
    "\t\t\t\t\t\tchunks[-1][1].append(fid)\n",
    "\t\t\t\t\tchunks[-1][3] = i0 + n - n0\n",
    "\t\t\t\t\tchunks.append([newdate,[fid],i,n])\n",
    "\t\t\t\tn += 1\n",
    "\t(olddate, fids0, i0, n0) = chunks[-1]\n",
    "\tchunks[-1][3] = i0 + n - n0\n",
    "\treturn chunks\n",
    "\n",
    "\n",
    "# # old version\n",
    "# def chunk_data(files):\n",
    "# \t\"\"\"divide data into daily chunks\"\"\"\n",
    "# \tn = 0\n",
    "# \twith netcdf.Dataset(files[0],'r') as fh:\n",
    "# \t\tTime = fh.variables['time']\n",
    "# \t\tCTime = fh.variables['time_bnds'][:].mean(axis=1)\n",
    "# \t\tdates = [cftime.num2date(T, Time.units, Time.calendar).strftime(\"%Y%m%d\") for T in CTime]\n",
    "# \t\tchunks = [[dates[0],[0],0,0]]\n",
    "# \tfor fid in range(len(files)):\n",
    "# \t\twith netcdf.Dataset(files[fid],'r') as fh:\n",
    "# \t\t\tCTime = fh.variables['time_bnds'][:].mean(axis=1)\n",
    "# \t\t\tdates = [cftime.num2date(T, Time.units, Time.calendar).strftime(\"%Y%m%d\") for T in CTime]\n",
    "# \t\t\tfor i,newdate in enumerate(dates):\n",
    "# \t\t\t\t(olddate, fids0, i0, n0) = chunks[-1]\n",
    "# \t\t\t\tif newdate != olddate:\n",
    "# \t\t\t\t\tif fids0[-1] != fid and i!=0:\n",
    "# \t\t\t\t\t\tchunks[-1][1].append(fid)\n",
    "# \t\t\t\t\tchunks[-1][3] = i0 + n - n0\n",
    "# \t\t\t\t\tchunks.append([newdate,[fid],i,n])\n",
    "# \t\t\t\tn += 1\n",
    "# \t(olddate, fids0, i0, n0) = chunks[-1]\n",
    "# \tchunks[-1][3] = i0 + n - n0\n",
    "# \treturn chunks\n",
    "\n",
    "\n",
    "def ReadinDataFixForMRES(filenames, t1, t2):\n",
    "\t\"\"\"The mres h4 file does not contain U250, V250 and T850, so using 3D data\"\"\"\n",
    "\twith netcdf.MFDataset(filenames, 'r', aggdim='time') as fh:\n",
    "\t\ttime\t   = fh.variables['time']\t\t\t\t   #Time\n",
    "\t\ttime\t   = cftime.num2date(time[t1:t2], time.units, calendar=time.calendar)\n",
    "\t\tlon\t\t\t= fh.variables['lon'][:]\t\t\t\t\t# Longitude\n",
    "\t\tlat\t\t\t= fh.variables['lat'][i1-1:i2+1]\t\t\t# Latitude\n",
    "\t\tlat_weight\t= fh.variables['gw'][i1:i2]\t\t\t\t    # Latitude weight\n",
    "\t\tpres\t\t= fh.variables['PSL'][t1:t2, i1:i2] / 100.0\t# Sea level pressure (hPa)\n",
    "\t\tU_10\t\t= fh.variables['U10'][t1:t2, i1:i2]\t\t    # 10-meter wind speed (m/s)\n",
    "\t\tu_vel_850\t= fh.variables['U850'][t1:t2, i1-1:i2+1]    # Zonal velocity at 850 hPa (m/s)\n",
    "\t\tv_vel_850\t= fh.variables['V850'][t1:t2, i1-1:i2+1]    # Zonal velocity at 850 hPa (m/s)\n",
    "\tfiles3D = glob.glob(directory_data+experiment_name+'.cam2.'+stream3D+'.*.nc')\n",
    "\tfiles3D.sort() #Sort the files on date\n",
    "\tfidi = files3D.index(filenames[0].replace(f\".{stream}.\", f\".{stream3D}.\"))\n",
    "\tfor fid in range(fidi,len(files3D)):\n",
    "\t\twith netcdf.Dataset(files3D[fid], 'r') as fh:\n",
    "\t\t\ttime3D = fh.variables['time']\n",
    "\t\t\ttime3D = cftime.num2date(time3D[:],time3D.units,calendar=time3D.calendar)\n",
    "\t\tif time[0] in time3D:\n",
    "\t\t\tfid0 = fid\n",
    "\t\tif time[-1] in time3D:\n",
    "\t\t\tfid1 = fid\n",
    "\t\t\tbreak\n",
    "\twith netcdf.MFDataset(files3D[fid0:fid1+1], 'r', aggdim='time') as fh:\n",
    "\t\ttime3D = fh.variables['time']\n",
    "\t\ttime3D = cftime.num2date(time3D[:],time3D.units,calendar=time3D.calendar)\n",
    "\t\tti, tf = time3D.searchsorted([time[0], time[-1]])\n",
    "\t\tassert all(time3D[ti:tf+1]==time), (\n",
    "\t\t\tf\"Could not obtain steps {time=} from {time3D=} in {stream3D} output.\")\n",
    "\t\tlev = fh.variables['lev'][:]\n",
    "\t\tassert max(lev) < 1200, f\"cannot assume lev has units hPa (max: {max(lev)=})\" # assume hPa unit\n",
    "\t\tl250 = abs(lev-250).argmin()\n",
    "\t\tl850 = abs(lev-850).argmin()\n",
    "\t\tprint(f\"Warning @ {[os.path.basename(f) for f in filenames]}\\n  reading U, V at lev={lev[l250]:.1f}hPa, \"\n",
    "\t\t\t+ f\"T at lev={lev[l850]:.1f}hPa instead of true pressure levels.\")\n",
    "\t\ttemp = fh.variables['T'][ti:tf+1, l850, i1:i2]\n",
    "\t\tu_vel_250 = fh.variables['U'][ti:tf+1, l250, i1-1:i2+1]\n",
    "\t\tv_vel_250 = fh.variables['V'][ti:tf+1, l250, i1-1:i2+1]\n",
    "\t\treturn time, lon, lat, lat_weight, pres, temp, U_10, u_vel_850, u_vel_250, v_vel_850, v_vel_250\n",
    "\n",
    "\n",
    "def ReadinData(filenames, x_diff, y_diff, t1, t2):\n",
    "\t# if experiment_name == 'mres_b.e10.B2000_CAM5.f05_t12.001':\n",
    "# \t\t(time, lon, lat, lat_weight, pres, temp, U_10, u_vel_850,\n",
    "# \t\tu_vel_250, v_vel_850, v_vel_250) = ReadinDataFixForMRES(filenames, t1, t2)\n",
    "# \telse:\n",
    "\twith netcdf.MFDataset(filenames, 'r', aggdim='time') as fh:\n",
    "\t\ttime\t   = fh.variables['time'][t1:t2]\t\t\t\t   #Time\n",
    "\t\tif 'time: mean' in getattr(fh['U850'], 'cell_methods', ''):\n",
    "\t\t\ttime = time - 0.5*dt\n",
    "\t\ttime\t   = cftime.num2date(time, fh['time'].units, fh['time'].calendar)\n",
    "\t\tlon\t\t   = fh.variables['lon'][:]\t\t\t\t\t   #Longitude\n",
    "\t\tlat\t\t   = fh.variables['lat'][i1-1:i2+1]\t\t\t\t #Latitude\n",
    "\t\tlat_weight = fh.variables['gw'][i1:i2]\t\t\t\t #Latitude weight\n",
    "\t\tpres\t   = fh.variables['PSL'][t1:t2, i1:i2] / 100.0\t #Sea level pressure (hPa)\n",
    "\t\tU_10\t   = fh.variables['U10'][t1:t2, i1:i2]\t\t #10-meter wind speed (m/s)\n",
    "\t\tu_vel_850  = fh.variables['U850'][t1:t2, i1-1:i2+1]\t #Zonal velocity at 850 hPa (m/s)\n",
    "\t\tv_vel_850  = fh.variables['V850'][t1:t2, i1-1:i2+1]\t #Zonal velocity at 850 hPa (m/s)\n",
    "\t\ttemp\t   = fh.variables['T850'][t1:t2, i1:i2]\t\t #Temperature 850 hPa\n",
    "\t\tu_vel_250  = fh.variables['U250'][t1:t2, i1-1:i2+1]\t #Zonal velocity at 250 hPa (m/s)\n",
    "\t\tv_vel_250  = fh.variables['V250'][t1:t2, i1-1:i2+1]\t #Zonal velocity at 250 hPa (m/s)\n",
    "\n",
    "\t#Add periodic boundaries\n",
    "\tlon_2, u_vel_850\t= PeriodicBoundaries3D(time, lon, lat, u_vel_850)\n",
    "\tlon_2, v_vel_850\t= PeriodicBoundaries3D(time, lon, lat, v_vel_850)\n",
    "\tlon_2, u_vel_250\t= PeriodicBoundaries3D(time, lon, lat, u_vel_250)\n",
    "\tlon, v_vel_250\t\t= PeriodicBoundaries3D(time, lon, lat, v_vel_250)\n",
    "\n",
    "\t#Determine the vorticity at 850 and 250 hPa\n",
    "\tvor_850\t\t\t= ma.masked_all((len(time), len(lat) - 2, len(lon) - 2))\n",
    "\tvor_250\t\t\t= ma.masked_all((len(time), len(lat) - 2, len(lon) - 2))\n",
    "\n",
    "\tfor time_i in range(len(time)):\n",
    "\t\t#Vorticity for the two level\n",
    "\t\tvor_850[time_i] = RelativeVorticity(u_vel_850[time_i], v_vel_850[time_i], x_diff, y_diff)\n",
    "\t\tvor_250[time_i] = RelativeVorticity(u_vel_250[time_i], v_vel_250[time_i], x_diff, y_diff)\n",
    "\t\n",
    "\t#Get the correct lon/lat dimensions\n",
    "\tlon, lat\t\t= lon[1:-1], lat[1:-1]\n",
    "\n",
    "\treturn time, lon, lat, lat_weight, pres, U_10, temp, vor_850, vor_250\n",
    "\n",
    "\n",
    "def PeriodicBoundaries2D(lon, lat, field, lon_grids = 1):\n",
    "\t\"\"\"Add periodic zonal boundaries for 2D field\"\"\"\n",
    "\n",
    "\t#Empty field with additional zonal boundaries\n",
    "\tlon_2\t\t\t= np.zeros(len(lon) + lon_grids * 2)\n",
    "\tfield_2\t\t\t= ma.masked_all((len(lat), len(lon_2)))\n",
    "\t\n",
    "\t#Get the left boundary, which is the right boundary of the original field\n",
    "\tlon_2[:lon_grids]\t= lon[-lon_grids:] - 360.0\n",
    "\tfield_2[:, :lon_grids]\t= field[:, -lon_grids:]\n",
    "\n",
    "\t#Same for the right boundary\n",
    "\tlon_2[-lon_grids:]\t= lon[:lon_grids] + 360.0\n",
    "\tfield_2[:, -lon_grids:] = field[:, :lon_grids]\n",
    "\n",
    "\t#And the complete field\n",
    "\tlon_2[lon_grids:-lon_grids]\t\t= lon\n",
    "\tfield_2[:, lon_grids:-lon_grids]\t= field\n",
    "\n",
    "\treturn lon_2, field_2\t\n",
    "\n",
    "\n",
    "def PeriodicBoundaries3D(time, lon, lat, field, lon_grids = 1):\n",
    "\t\"\"\"Add periodic zonal boundaries for 3D field\"\"\"\n",
    "\n",
    "\t#Empty field with additional zonal boundaries\n",
    "\tlon_2\t\t\t\t= np.zeros(len(lon) + lon_grids * 2)\n",
    "\tfield_2\t\t\t\t= ma.masked_all((len(time), len(lat), len(lon_2)))\n",
    "\t\n",
    "\t#Get the left boundary, which is the right boundary of the original field\n",
    "\tlon_2[:lon_grids]\t\t= lon[-lon_grids:] - 360.0\n",
    "\tfield_2[:, :, :lon_grids]\t= field[:, :, -lon_grids:]\n",
    "\n",
    "\t#Same for the right boundary\n",
    "\tlon_2[-lon_grids:]\t\t= lon[:lon_grids] + 360.0\n",
    "\tfield_2[:, :, -lon_grids:]\t= field[:, :, :lon_grids]\n",
    "\n",
    "\t#And the complete field\n",
    "\tlon_2[lon_grids:-lon_grids]\t\t= lon\n",
    "\tfield_2[:, :, lon_grids:-lon_grids]\t\t= field\n",
    "\n",
    "\treturn lon_2, field_2\t\n",
    "\n",
    "\n",
    "def RelativeVorticity(u_vel, v_vel, x_diff, y_diff):\n",
    "\t\"\"\"Determines the relative vorticity of the field\"\"\"\n",
    "\n",
    "\t#Take the meridional difference of the zonal wind\n",
    "\tu_vel_diff\t= u_vel[2:] - u_vel[:-2]\n",
    "\tu_vel_diff\t= u_vel_diff[:, 1:-1]\n",
    "\n",
    "\t#Take the zonal difference of the meridional wind\n",
    "\tv_vel_diff\t= v_vel[:, 2:] - v_vel[:, :-2]\n",
    "\tv_vel_diff\t= v_vel_diff[1:-1]\n",
    "\n",
    "\t#Determine the relative vorticity\n",
    "\tvorticity\t= (v_vel_diff / x_diff) - (u_vel_diff / y_diff)\n",
    "\n",
    "\treturn vorticity\n",
    "\n",
    "\n",
    "def Distance(lon_1, lat_1, lon_2, lat_2):\n",
    "\t\"\"\"Returns distance (m) of two points located at the globe coordinates need input in degrees\"\"\"\n",
    "\n",
    "\t#Convert to radians\n",
    "\tlon_1, lat_1, lon_2, lat_2 = map(radians, [lon_1, lat_1, lon_2, lat_2]) \n",
    "\n",
    "\t#Haversine formula \n",
    "\td_lon\t= lon_2 - lon_1 \n",
    "\td_lat\t= lat_2 - lat_1 \n",
    "\ta\t= math.sin(d_lat/2.0)**2 + math.cos(lat_1) * math.cos(lat_2) * math.sin(d_lon/2.0)**2\n",
    "\tc\t= 2.0 * math.asin(sqrt(a)) \n",
    "\t\n",
    "\treturn c * RADIUSEARTH #Distance between two points in meter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e56b807-41a8-479b-a06b-2a303fc7e64d",
   "metadata": {},
   "source": [
    "#### First find suitable TC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151790eb-f364-405c-9285-4feb524ed285",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(directory_data+experiment_name+'.cam2.'+stream+'.*.nc')\n",
    "files.sort() #Sort the files on date\n",
    "files = files[0:2] #[6:372]\n",
    "tasks = chunk_data(files)\n",
    "len(tasks), files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91882d7e-aa44-4840-9d3e-50c6bee06eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine grid properties\n",
    "\n",
    "with netcdf.Dataset(files[0], 'r') as fh:\n",
    "\tlats0 = fh['lat'][:]\n",
    "\tlons0 = fh['lon'][:]\n",
    "\ttimei = fh['time'][0]\n",
    "\tdt = fh['time'][1] - fh['time'][0]\n",
    "\tassert np.all(lats0[1:] > lats0[:-1]), \"latitude does not increase\"\n",
    "\ti1 = lats0.searchsorted(LATMIN) - 1 # lat. index of 60S\n",
    "\ti2 = lats0.searchsorted(LATMAX) + 1 # lat. index of 60N\n",
    "\tdlat = np.mean(np.diff(lats0)) # meridional grid cell size [degrees N]\n",
    "\tdlon = np.mean(np.diff(lons0)) # zonal grid cell size [degrees E]\n",
    "with netcdf.Dataset(files[-1], 'r') as fh:\n",
    "\ttry: # get last timestamp \n",
    "\t\ttimef = fh['time'][-1]\n",
    "\texcept IndexError: # read one before last file if last file is empty\n",
    "\t\twith netcdf.Dataset(files[-2],'r') as fh2:\n",
    "\t\t\ttimef = fh2['time'][-1]\n",
    "\ttotal_num_time_steps = (timef - timei)//dt + 1\n",
    "\n",
    "fh = netcdf.Dataset(gridfile, 'r')\n",
    "\n",
    "#Writing data to correct variable\n",
    "lon_grid\t= fh.variables['lon'][:]\t#Longitude\n",
    "lat_grid\t= fh.variables['lat'][i1-1:i2+1]  #Latitude\t  \n",
    "grid_x\t\t= fh.variables['DX'][i1-1:i2+1]\t  #Zonal length of grid cell  \n",
    "grid_y\t\t= fh.variables['DY'][i1-1:i2+1]\t  #Meridional length of grid cell\t  \n",
    "\n",
    "fh.close()\n",
    "\n",
    "# plot\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "plot = ax.contourf(lon_grid, lat_grid, grid_x, \n",
    "            transform=ccrs.PlateCarree())\n",
    "ax.gridlines(draw_labels=True)\n",
    "ax.coastlines()\n",
    "ax.set_title('grid_x')\n",
    "ax.fig.colorbar(plot)\n",
    "ax.show()\n",
    "####\n",
    "\n",
    "lon_2, grid_x\t= PeriodicBoundaries2D(lon_grid, lat_grid, grid_x)\n",
    "lon, grid_y = PeriodicBoundaries2D(lon_grid, lat_grid, grid_y)\n",
    "\n",
    "#Generate for each grid cell the difference length\n",
    "x_diff\t\t= 0.5 * grid_x[:, 2:] + 0.5 * grid_x[:, :-2] + grid_x[:, 1:-1]\n",
    "y_diff\t\t= 0.5 * grid_y[2:] + 0.5 * grid_y[:-2] + grid_y[1:-1]\n",
    "x_diff\t= x_diff[1:-1]\n",
    "y_diff\t= y_diff[:, 1:-1]\n",
    "\n",
    "# plot\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "plot = ax.contourf(lon_grid, lat_grid, x_diff, \n",
    "            transform=ccrs.PlateCarree())\n",
    "ax.gridlines(draw_labels=True)\n",
    "ax.coastlines()\n",
    "ax.set_title('x_diff')\n",
    "ax.fig.colorbar(plot)\n",
    "ax.show()\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de01d8-7eb0-4535-9172-d287e72cab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tasks[0]\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4631be-0784-40f8-b5da-2150e1925ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkdate, filelist, t0, t1 = task\n",
    "try:\n",
    "    filenames = [files[fid] for fid in filelist]\n",
    "except IndexError:\n",
    "    print(f\"IndexError: task {task} failed. {len(files)=}\")\n",
    "    # return\n",
    "#print(f\"[{datetime.datetime.now()}] File {filelist}, steps {t0} - {t1}\", flush=True)\n",
    "\n",
    "#Counters\n",
    "hour_counter\t\t= 0\n",
    "RV_max_max_day\t\t= 0\n",
    "\n",
    "#For each day (8x3 hour) determine the pressure lows\n",
    "time_RV_max\t\t= ma.masked_all(NOUT)\n",
    "RV_max_coor_lon\t\t= ma.masked_all((NOUT, 800))\n",
    "RV_max_coor_lat\t\t= ma.masked_all((NOUT, 800))\n",
    "temp_anom_all\t\t= ma.masked_all((NOUT, 800))\n",
    "time, lon, lat, lat_weight, pres, U_10, temp, vor_850, vor_250\t= ReadinData(filenames, x_diff, y_diff, t0, t1)\n",
    "assert (lon_grid.shape == lon.shape) and (lat_grid[1:-1].shape == lat.shape), (\n",
    "    f'Grid in {gridfile} does not match data.')\n",
    "\n",
    "#Last elements can not be determined\n",
    "x_diff\t= x_diff[1:-1]\n",
    "y_diff\t= y_diff[:, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6624e-11e2-480d-91ac-966e6f44f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "avor_850 = vor_850 * np.sign(lat)\n",
    "avor_850_max = max(avor_850)\n",
    "ti = 0\n",
    "latid, lonid = np.argmax(avor_850[ti])\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "plot = ax.contourf(lon, lat, avor_850[ti], \n",
    "            levels=np.arange(6e-5, avor_850_max+6e-5, 6e-5), \n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap='hot_r')\n",
    "ax.scatter(lonid, latid, transform=ccrs.PlateCarree(), marker='+', c='b')\n",
    "ax.gridlines(draw_labels=True)\n",
    "ax.coastlines()\n",
    "ax.set_title('avor_850')\n",
    "ax.fig.colorbar(plot)\n",
    "ax.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8993d1ef-dbf8-4e24-b031-ddb03c57f22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef05517-ac56-4fb7-b983-f0138a568e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for time_i in range(len(time)):\n",
    "    date_str = time[time_i].strftime('%Y-%m-%d')\n",
    "    if os.path.exists(directory+'RV_Max/RV_Max_Coordinates_'+date_str+'.nc'):\n",
    "        hour_counter\t= 0\n",
    "        print('skip creating RV_Max_Coordinates_'+date_str+'.nc (already exists)', flush=True)\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"[{datetime.datetime.now()}] MFFile ids: {filelist}, step: {time_i+t0:03d} -> {date_str} ({t0:03d}-{t1:03d})\", flush=True)\n",
    "    \n",
    "    #Loop over each 3-hourly field\n",
    "    lat_index_EQ\t= np.where(lat >= 0.0)[0][0]\n",
    "\n",
    "    #Get all the indices where the (absolute) vorticity is larger than 6 * 10^-5 \n",
    "    index_NH\t= np.where(vor_850[time_i, lat_index_EQ:] >= RVTHRESHOLD)\n",
    "    lat_index_NH\t= index_NH[0] + lat_index_EQ\n",
    "    lon_index_NH\t= index_NH[1]\n",
    "    index_SH\t= np.where(-vor_850[time_i, :lat_index_EQ] >= RVTHRESHOLD)\n",
    "    lat_index_SH\t= index_SH[0]\n",
    "    lon_index_SH\t= index_SH[1]\n",
    "\n",
    "    #Save all the indices in 1 array (SH + NH)\n",
    "    lon_index\t= np.insert(lon_index_SH, len(lon_index_SH), lon_index_NH)\n",
    "    lat_index\t= np.insert(lat_index_SH, len(lat_index_SH), lat_index_NH)\n",
    "\n",
    "    #Save all the indices in 1 array (SH + NH)\n",
    "    lon_index\t= np.insert(lon_index_SH, len(lon_index_SH), lon_index_NH)\n",
    "    lat_index\t= np.insert(lat_index_SH, len(lat_index_SH), lat_index_NH)\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    #Empty arrays to save the RV maxima\n",
    "    RV_max_index_lon\t= []\n",
    "    RV_max_index_lat\t= []\n",
    "    temp_anom\t\t= []\n",
    "\n",
    "    for index_i in range(len(lat_index)):\n",
    "        #Loop over each point with a negative sea-level pressure\n",
    "        lon_i\t\t= lon_index[index_i]\n",
    "        lat_i\t\t= lat_index[index_i]\n",
    "\n",
    "        #Check vorticity criterium\n",
    "        vor_850_TC\t= vor_850[time_i, lat_i, lon_i] * np.sign(lat[lat_i])\n",
    "        vor_250_TC\t= vor_250[time_i, lat_i, lon_i] * np.sign(lat[lat_i])\n",
    "\n",
    "        if vor_850_TC < RVTHRESHOLD:\n",
    "            #Relative vorticity is too low\n",
    "            continue\n",
    "\n",
    "        if (vor_850_TC - vor_250_TC) < RVDIFFTHRESHOLD:\n",
    "            #No evidence for warm core\n",
    "            continue\n",
    "\n",
    "        #Get the horizontal velocity (8x8) around the eye\n",
    "        lon_east\t= lon_i + round(FIELDSIZE/(2*dlon)) + 1\n",
    "        lon_west\t= lon_i - round(FIELDSIZE/(2*dlon))\n",
    "        lat_north\t= lat_i + round(FIELDSIZE/(2*dlat)) + 1\n",
    "        lat_south\t= lat_i - round(FIELDSIZE/(2*dlat))\n",
    "\n",
    "        if lat_south < 0:\n",
    "            lat_south = 0\n",
    "\n",
    "        #Get the dimensions for the lat field\n",
    "        lat_field\t= lat[lat_south:lat_north]\n",
    "        weight\t\t= lat_weight[lat_south:lat_north]\n",
    "        weight\t\t= weight / np.sum(weight)\n",
    "        lon_field\t= np.zeros(lon_east - lon_west)\n",
    "        temp_field\t= ma.masked_all((len(lat_field), len(lon_field)))\n",
    "        U_10_field\t= ma.masked_all((len(lat_field), len(lon_field)))\n",
    "\n",
    "        if lon_east > len(lon):\n",
    "            #Eastern part is on eastern hemisphere\n",
    "            lon_1\t\t\t\t= lon[lon_west:]\n",
    "            lon_2\t\t\t\t= lon[:lon_east - len(lon)] + 360.0\n",
    "            lon_field[:len(lon_1)]\t\t= lon_1\n",
    "            lon_field[len(lon_1):]\t\t= lon_2\n",
    "            temp_field[:, :len(lon_1)]\t= temp[time_i, lat_south:lat_north, lon_west:]\n",
    "            temp_field[:, len(lon_1):]\t= temp[time_i, lat_south:lat_north, :lon_east - len(lon)]\n",
    "            U_10_field[:, :len(lon_1)]\t= U_10[time_i, lat_south:lat_north, lon_west:]\n",
    "            U_10_field[:, len(lon_1):]\t= U_10[time_i, lat_south:lat_north, :lon_east - len(lon)]\n",
    "\n",
    "        elif lon_west < 0:\n",
    "            #Western part is on western hemisphere\n",
    "            lon_1\t\t\t\t= lon[lon_west:] - 360.0\n",
    "            lon_2\t\t\t\t= lon[:lon_east]\n",
    "            lon_field[:len(lon_1)]\t\t= lon_1\n",
    "            lon_field[len(lon_1):]\t\t= lon_2\n",
    "            temp_field[:, :len(lon_1)]\t= temp[time_i, lat_south:lat_north, lon_west:]\n",
    "            temp_field[:, len(lon_1):]\t= temp[time_i, lat_south:lat_north, :lon_east]\n",
    "            U_10_field[:, :len(lon_1)]\t= U_10[time_i, lat_south:lat_north, lon_west:]\n",
    "            U_10_field[:, len(lon_1):]\t= U_10[time_i, lat_south:lat_north, :lon_east]\n",
    "\n",
    "        else:\n",
    "            #Normal field can be retained\n",
    "            lon_field\t= lon[lon_west:lon_east]\n",
    "            temp_field\t= temp[time_i, lat_south:lat_north, lon_west:lon_east]\n",
    "            U_10_field\t= U_10[time_i, lat_south:lat_north, lon_west:lon_east]\n",
    "\n",
    "        #Determine the spatial average over the field\n",
    "        temp_mean\t= np.mean(temp_field, axis = 1)\n",
    "        temp_mean\t= np.sum(temp_mean * weight)\n",
    "\n",
    "        #Get the temperature anomaly of the given point\n",
    "        lon_index_2 = (fabs(lon_field - lon[lon_i])).argmin()\n",
    "        lat_index_2 = (fabs(lat_field - lat[lat_i])).argmin()\n",
    "        temp_anom_TC\t= temp_field[lat_index_2, lon_index_2] - temp_mean\n",
    "\n",
    "        if temp_anom_TC < CORETEMPTHRESHOLD:\n",
    "            #No warm core\n",
    "            continue\n",
    "\n",
    "        #Check whether the 10-m wind speed exceeds threshold \n",
    "        U_10_treshold = False\n",
    "\n",
    "        for lat_j in range(len(lat_field)):\n",
    "            for lon_j in range(len(lon_field)):\n",
    "                #Check whether the 10-m wind speeds exceeds 10 m/s\n",
    "                if U_10_field[lat_j, lon_j] < U10THRESHOLD:\n",
    "                    continue\n",
    "\n",
    "                #Check the 10-m wind speed in a 100-km search radius\n",
    "                distance\t= Distance(lon[lon_i], lat[lat_i], lon_field[lon_j], lat_field[lat_j]) / 1000.0\n",
    "\n",
    "                if distance <= U10THRESHOLD_MAXRADIUS:\n",
    "                    #10-m wind speed exceeds treshold within 100 km\n",
    "                    U_10_treshold = True\n",
    "                    break\n",
    "\n",
    "            if U_10_treshold:\n",
    "                #Threshold is reached, stop search\n",
    "                break\n",
    "\n",
    "        if U_10_treshold == False:\n",
    "            #The 10-m wind speed treshold is not valid\n",
    "            continue\n",
    "\n",
    "        #Save the coordinates and the anomalies\n",
    "        RV_max_index_lon.append(lon_i)\n",
    "        RV_max_index_lat.append(lat_i)\n",
    "        temp_anom.append(temp_anom_TC)\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    distance_RV = True\n",
    "    RV_index_start\t= 0\n",
    "\n",
    "    while distance_RV:\n",
    "        #Check RV maxima in the neighbourhood\n",
    "        RV_dlat_min = np.ceil(1000*RVDISTMIN*180/(np.pi*RADIUSEARTH))\n",
    "        for RV_i in range(RV_index_start, len(RV_max_index_lon)):\n",
    "            for RV_j in range(RV_i + 1, len(RV_max_index_lon)):\n",
    "                #Get the coordinates\n",
    "                lon_RV_1\t= lon[RV_max_index_lon[RV_i]]\n",
    "                lat_RV_1\t= lat[RV_max_index_lat[RV_i]]\n",
    "                lon_RV_2\t= lon[RV_max_index_lon[RV_j]]\n",
    "                lat_RV_2\t= lat[RV_max_index_lat[RV_j]]\n",
    "\n",
    "                if fabs(lat_RV_1 - lat_RV_2) > RV_dlat_min:\n",
    "                    #Points are too far apart\n",
    "                    continue\n",
    "\n",
    "                #Determine the distance (km) between the two points\n",
    "                distance\t= Distance(lon_RV_1, lat_RV_1, lon_RV_2, lat_RV_2) / 1000.0\n",
    "\n",
    "                if distance < RVDISTMIN:\n",
    "                    #Distance between pressure minima must be at least 250 km\n",
    "                    #Select the one with the lowest sea-level pressure\n",
    "                    pres_1\t\t= pres[time_i, RV_max_index_lat[RV_i], RV_max_index_lon[RV_i]]\n",
    "                    pres_2\t\t= pres[time_i, RV_max_index_lat[RV_j], RV_max_index_lon[RV_j]]\n",
    "\n",
    "                    #Retain the one with the highest RV\n",
    "                    index_min\t= np.argmin([pres_1, pres_2])\n",
    "\n",
    "                    if index_min == 0:\n",
    "                        #First point has lowest PSL, remove second\n",
    "                        RV_max_index_lon\t= np.delete(RV_max_index_lon, RV_j)\n",
    "                        RV_max_index_lat\t= np.delete(RV_max_index_lat, RV_j)\n",
    "                        temp_anom\t\t= np.delete(temp_anom, RV_j)\n",
    "\n",
    "                    else:\n",
    "                        #Second point has lowest PSL, remove first\n",
    "                        RV_max_index_lon\t= np.delete(RV_max_index_lon, RV_i)\n",
    "                        RV_max_index_lat\t= np.delete(RV_max_index_lat, RV_i)\n",
    "                        temp_anom\t\t= np.delete(temp_anom, RV_i)\n",
    "\n",
    "                    #Break the j-loop\n",
    "                    RV_j = -1\n",
    "                    break\n",
    "\n",
    "            #Check whether the j-loop was terminated\n",
    "            if RV_j == -1:\n",
    "                #Break i-loop and start over with the reduced list\n",
    "                RV_j = 0\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                #j-loop is completed, raise starting index by 1\n",
    "                RV_index_start += 1\n",
    "\n",
    "            if RV_i == len(RV_max_index_lon) - 1:\n",
    "                #i-loop is finished, stop the while\n",
    "                distance_RV = False\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "\n",
    "    #Save the indices (note that the index has a base starting at 60S)\n",
    "    time_RV_max[hour_counter]\t\t\t\t= cftime.date2num(time[time_i], 'Days since 0001-01-01 00:00:00 UTC', 'noleap')\n",
    "    RV_max_coor_lon[hour_counter, :len(RV_max_index_lon)]\t= RV_max_index_lon\n",
    "    RV_max_coor_lat[hour_counter, :len(RV_max_index_lat)]\t= RV_max_index_lat\n",
    "    temp_anom_all[hour_counter, :len(temp_anom)]\t\t= temp_anom\n",
    "\n",
    "    if len(RV_max_index_lon) > RV_max_max_day:\n",
    "        #New hourly maximum of pressure minima\n",
    "        RV_max_max_day = len(RV_max_index_lon)\n",
    "\n",
    "    #Update hour counter\n",
    "    hour_counter += 1\n",
    "\n",
    "    if hour_counter == NOUT:\n",
    "        #Remove masked arrays\n",
    "        RV_max_coor_lon\t\t= RV_max_coor_lon[:, :RV_max_max_day + 1]\n",
    "        RV_max_coor_lat\t\t= RV_max_coor_lat[:, :RV_max_max_day + 1]\n",
    "        temp_anom_all\t\t= temp_anom_all[:, :RV_max_max_day + 1]\n",
    "\n",
    "        # write data\n",
    "        HEAT_data = netcdf.Dataset(directory+'RV_Max/RV_Max_Coordinates_'+date_str+'.nc', 'w')\n",
    "        HEAT_data.createDimension('time', len(time_RV_max))\n",
    "        HEAT_data.createDimension('number_lows', len(RV_max_coor_lon[0]))\n",
    "        HEAT_data.createVariable('time', float, ('time'), zlib=True)\n",
    "        HEAT_data.createVariable('number_lows', float, ('number_lows'), zlib=True)\n",
    "        HEAT_data.createVariable('lon_index', float, ('time', 'number_lows'), zlib=True)\n",
    "        HEAT_data.createVariable('lat_index', float, ('time', 'number_lows'), zlib=True)\n",
    "        HEAT_data.createVariable('TEMP', float, ('time', 'number_lows'), zlib=True)\n",
    "        HEAT_data.variables['lon_index'].longname\t= 'Longitude index of low'\n",
    "        HEAT_data.variables['lat_index'].longname\t= 'Latitude index of low (0 = 60.2S)'\n",
    "        HEAT_data.variables['TEMP'].longname\t\t= 'Temperature anomaly w.r.t. 8x8 mean'\n",
    "        HEAT_data.variables['time'].units\t\t= 'Days since 0001-01-01 00:00:00 UTC'\n",
    "        HEAT_data.variables['time'].calendar\t= 'noleap'\n",
    "        HEAT_data.variables['TEMP'].units\t\t= 'deg C'\t\n",
    "        HEAT_data.variables['time'][:]\t\t\t= time_RV_max\n",
    "        HEAT_data.variables['number_lows'][:]\t= np.arange(len(RV_max_coor_lon[0])) + 1\n",
    "        HEAT_data.variables['lon_index'][:]\t\t= RV_max_coor_lon\n",
    "        HEAT_data.variables['lat_index'][:]\t\t= RV_max_coor_lat\n",
    "        HEAT_data.variables['TEMP'][:]\t\t\t= temp_anom_all\n",
    "        print(\"Created {}\".format(HEAT_data.filepath()), flush=True)\n",
    "        HEAT_data.close()\n",
    "        \n",
    "\n",
    "        #Reset the counters\n",
    "        hour_counter\t= 0\n",
    "        RV_max_max_day\t= 0\n",
    "    \n",
    "        #Make empty array for the following day\n",
    "        time_RV_max\t\t= ma.masked_all(NOUT)\n",
    "        RV_max_coor_lon = ma.masked_all((NOUT, 800))\n",
    "        RV_max_coor_lat = ma.masked_all((NOUT, 800))\n",
    "        temp_anom_all\t= ma.masked_all((NOUT, 800))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff9cc4-2eae-4d2a-a26f-b5a2ed8df577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
